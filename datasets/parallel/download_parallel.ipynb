{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "\n",
    "# URL of the ZIP file\n",
    "zip_url = \"https://github.com/reddy-lab-code-research/MuST-CoST/raw/refs/heads/main/CoST_data.zip\"\n",
    "\n",
    "# Local directory to extract the files\n",
    "extract_path = \".\"\n",
    "\n",
    "# Download the ZIP file\n",
    "response = requests.get(zip_url)\n",
    "response.raise_for_status()  # Raise an error for failed requests\n",
    "\n",
    "# Open the ZIP file from the response content\n",
    "with zipfile.ZipFile(io.BytesIO(response.content), 'r') as zip_ref:\n",
    "    # Create the extraction directory if it doesn't exist\n",
    "    os.makedirs(extract_path, exist_ok=True)\n",
    "    # Extract all contents\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(f\"Files extracted to: {extract_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## snippet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Path to the directory containing processed data\n",
    "path = './CoST_data_release/processed_data/snippet_data'\n",
    "\n",
    "# Mapping of programming languages to their file extensions\n",
    "code_formats = {\n",
    "    'C': '.c',\n",
    "    'C++': '.cpp',\n",
    "    'C#': '.cs',\n",
    "    'Java': '.java',\n",
    "    'Javascript': '.js',\n",
    "    'PHP': '.php',\n",
    "    'Python': '.py'\n",
    "}\n",
    "\n",
    "\n",
    "all_indices = []\n",
    "all_dict = {k: {} for k in code_formats}\n",
    "\n",
    "\n",
    "\n",
    "# Iterate through each subdirectory in the specified path\n",
    "for p in glob.glob(os.path.join(path, '*')):\n",
    "    folder_name = os.path.basename(p)\n",
    "    lang1, lang2 = folder_name.split('-')\n",
    "    \n",
    "    for lang in [lang1, lang2]:\n",
    "        if lang not in code_formats:\n",
    "            print(f\"Skipping unknown language: {lang}\")\n",
    "            continue\n",
    "        \n",
    "        indices_temp = []\n",
    "        # Process each data split (train, test, val)\n",
    "        for split in ['train', 'test', 'val']:\n",
    "            map_file_path = os.path.join(p, f'{split}-{lang}-map.jsonl')\n",
    "            code_file_path = os.path.join(p, f'{split}-{folder_name}-tok{code_formats[lang]}')\n",
    "            \n",
    "            # Check if files exist\n",
    "            if not os.path.exists(map_file_path):\n",
    "                print(f\"Skipping missing file: {map_file_path}\")\n",
    "                continue\n",
    "            \n",
    "            if not os.path.exists(code_file_path):\n",
    "                print(f\"Skipping missing file: {code_file_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Read the files\n",
    "            with open(map_file_path, 'r') as f:\n",
    "                indices = f.readlines()\n",
    "                indices = [i.strip() for i in indices]\n",
    "            with open(code_file_path, 'r') as f:\n",
    "                codes = f.readlines()\n",
    "            # Add logic here to process `indices` and `codes` if needed\n",
    "            \n",
    "            indices_temp.extend(indices)\n",
    "            \n",
    "            dict_temp = dict(zip(indices, codes))\n",
    "            for key, value in dict_temp.items():\n",
    "                if key not in all_dict[lang]:\n",
    "                    all_dict[lang][key] = value\n",
    "\n",
    "            \n",
    "        # print(folder_name)\n",
    "        # print(len(indices_temp))\n",
    "        all_indices.append(indices_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices_new = []\n",
    "for indices_temp in all_indices:\n",
    "    indices_temp = [i.split('-')[0] + '-' + i.split('-')[-1] for i in indices_temp]\n",
    "    all_indices_new.append(indices_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_of_all_lists(list_of_lists):\n",
    "    # Start with the set of the first list\n",
    "    intersection = set(list_of_lists[0])\n",
    "    \n",
    "    # Iterate over the rest of the lists and keep intersecting\n",
    "    for lst in list_of_lists[1:]:\n",
    "        intersection &= set(lst)  # Keep the intersection with the next list\n",
    "    \n",
    "    return list(intersection)  # Return as a list (optional)\n",
    "\n",
    "\n",
    "common_sinppet_ids = intersection_of_all_lists(all_indices_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Path to the directory containing the JSONL files\n",
    "input_path = 'CoST_data_release/processed_data/map_data'\n",
    "output_path = 'code_snippets'\n",
    "\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process each file\n",
    "def process_file(file_path, output_dir):\n",
    "    language = file_path.split('/')[-1].split('-')[0]  # Extract language from file name\n",
    "\n",
    "    output_dir_lang = os.path.join(output_dir, language)\n",
    "    os.makedirs(output_dir_lang, exist_ok=True)\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "        for line in infile:\n",
    "            entry = json.loads(line)\n",
    "            # Extract the base ID from the idx (e.g., \"1010-2\" from \"1010-C#-2\")\n",
    "            base_id = entry['idx'].split('-')[0] + '-' + entry['idx'].split('-')[2]\n",
    "            if base_id in common_sinppet_ids:\n",
    "                # Save each entry to a separate file based on its base_id\n",
    "                del entry['bpe']\n",
    "                del entry['comment_bpe']\n",
    "                del entry['desc_bpe']\n",
    "                output_file = os.path.join(output_dir_lang, f\"{base_id}.json\")\n",
    "                with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "                    json.dump(entry, outfile)\n",
    "                    outfile.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the files in the input directory\n",
    "for file_name in os.listdir(input_path):\n",
    "    if file_name.endswith('mapping-tok.jsonl'):\n",
    "        file_path = os.path.join(input_path, file_name)\n",
    "        process_file(file_path, output_path)\n",
    "print(f\"Filtered data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_formats = {\n",
    "    'C': '.c',\n",
    "    'C++': '.cpp',\n",
    "    'C#': '.cs',\n",
    "    'Java': '.java',\n",
    "    'Javascript': '.js',\n",
    "    'PHP': '.php',\n",
    "    'Python': '.py'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'code_snippets'\n",
    "\n",
    "all_langs = code_formats.keys()\n",
    "\n",
    "all_filenames = os.listdir(os.path.join(input_path, 'C'))\n",
    "# Iterate through the files in the input directory\n",
    "for file_name in all_filenames:\n",
    "    \n",
    "    for lang in all_langs:\n",
    "        \n",
    "        file_path = os.path.join((os.path.join(input_path, lang)), file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "            for line in infile:\n",
    "                entry = json.loads(line)\n",
    "                print(lang, ':', entry['snippet'])\n",
    "\n",
    "    print('Rust : ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
