## Code-logit-lens 

To interpret latent embeddings, we use the [logit lens](https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens).

#### Code Keywords and Built-ins

We included keywords and built-ins for different programming languages in the [datasets/keywords](datasets/keywords). Built-ins include: primitive types, macros, modules, collections, containers, and built-in functions, excluding keywords.

## Code-MEXA 
To calculate cross-lingual alignment between programming languages, we use MEXA.

## Code-LAPE

To calculate language-specific neurons, we use LAPE.
